{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Configuration data\n",
      "Loading the blog contents\n",
      "Splitting the blog content into smaller chunks\n",
      "\n",
      "Inserted 7 documents.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# Load OPENAI & Langsmith API Keys\n",
    "print(\"Loading Configuration data\")\n",
    "\n",
    "def load_config(configfile):\n",
    "    with open(configfile, 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        return config\n",
    "\n",
    "config = load_config('apikeys.yaml')\n",
    "\n",
    "ASTRA_DB_APPLICATION_TOKEN = config['apikeys']['astra_vector_db']\n",
    "ASTRA_DB_API_ENDPOINT = \"https://3787f08e-f351-42f4-b3bd-cfb6f9f924b2-us-east1.apps.astra.datastax.com\"\n",
    "ASTRA_DB_KEYSPACE = \"default_keyspace\"\n",
    "LANGCHAIN_API_KEY = config['apikeys']['langsmith']\n",
    "OPENAI_API_KEY = config['apikeys']['openai']\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_API_KEY'] = LANGCHAIN_API_KEY\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "\n",
    "print(\"Loading the blog contents\") \n",
    "# Load, chunk and index the contents of the blog.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.jeyamohan.in/200801/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"td-post-content tagdiv-type\",)\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(\"Splitting the blog content into smaller chunks\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vstore = AstraDBVectorStore(\n",
    "    embedding = embeddings,\n",
    "    namespace = ASTRA_DB_KEYSPACE,\n",
    "    collection_name=\"docs\",\n",
    "    token = ASTRA_DB_APPLICATION_TOKEN,\n",
    "    api_endpoint = ASTRA_DB_API_ENDPOINT\n",
    ")\n",
    "\n",
    "inserted_ids = vstore.add_documents(splits)\n",
    "print(f\"\\nInserted {len(inserted_ids)} documents.\")\n",
    "\n",
    "retriever = vstore.as_retriever()\n",
    "prompt = hub.pull(\"rag_detailed\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': '-', 'lc_hub_repo': 'rag_detailed', 'lc_hub_commit_hash': '9f9d46ca7e12e0ec2b305631beebd191f5f7b35150f79bfba731a867a2b22a7a'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If the answer cannot be found in the context, just say that you don't know. If you don't know the answer, just say that you don't know. Be as detailed as possible with the answers.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "நம் கல்விமுறையின் அடிப்படைச் சிக்கல் என்னவென்றால், சுயசிந்தனை (அல்லது சுயமாக சிந்தித்து, புதிய கருத்துகளை உருவாக்குதல்) கற்பிக்கப்படுவதில்லை. மாணவர்கள் கற்றுக்கொள்வது முழுமையாக புத்தகங்களில் உள்ளவற்றை நினைவில் கொண்டு எழுதுவதையே ஆகும். இது அவர்களை சிந்திக்காமல், நினைவில் வைத்துக்கொள்ளும் இயந்திரங்களாக மாற்றுகிறது. மேலும், இந்தியக் கல்விமுறையின் மற்றொரு முக்கிய சிக்கல், மதிப்பெண்களை வழங்குவதில் வெளிப்படைத்தன்மையை பேணுவதும், தவறுகளை நிரூபிப்பதில் உள்ள சிரமமும் ஆகும். இதனால் மாணவர்கள் தங்கள் கருத்தை வெளிப்படுத்தாதவர்களாகவும், சுருக்கமாக சிந்திக்கத் தெரியாதவர்களாகவும் உருவாகின்றனர்.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"நம் கல்விமுறையின் அடிப்படைச் சிக்கல்?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "தத்துவப்படுத்துதல் என்பது ஒரு நுண்ணறிவு செயலாகும். இதை நுண்சிந்தனை என்றும் அழைக்கலாம். இது அடிப்படையில் தர்க்கத்தை மேற்கொண்டு சிந்தனையை விரிவாக்குதல், புதியவற்றை உருவாக்குதல், மற்றும் முற்றிலும் புதிய தளத்திற்கு தாவிச் செல்லுதல் போன்ற செயல்களை உள்ளடக்கியது. இதன் மூலம், நமக்கு அளிக்கப்பட்ட தகவல்களில் உள்ள தர்க்கத்தை பயன்படுத்தி, அச்சிந்தனையை நுண்ணறிவுடன் விரிவாக்க முடியும். \n",
      "\n",
      "இது ஒரு மூன்றடுக்கு செயலாகும்:\n",
      "1. தர்க்கம் - அளிக்கப்பட்டவற்றில் உள்ள தர்க்கத்தை மேற்கொண்டு முன்னெடுத்து விரிவாக்குதல்.\n",
      "2. கற்பனை - புதியவற்றை உருவாக்குதல்.\n",
      "3. நுண்ணுணர்வு - முற்றிலும் புதிய தளத்திற்கு தாவிச் செல்லுதல்.\n",
      "\n",
      "தத்துவ வகுப்புகளில் இந்நுண்சிந்தனையை அல்லது தத்துவப்படுத்தலுக்கு பயிற்சி அளிக்கப்படுகிறது.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"தத்துவப்படுத்துதல் என்று சொல்வது என்ன?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "நம்முடைய கல்லூரிகளின் நிலை மிகுந்த சிரமமானதாகும். மாணவர்கள் குறிப்பாக புத்தகங்களில் உள்ளவற்றை நினைவில் கொண்டு எழுதுவதில் மட்டுமே திறமைசாலிகள். சுயசிந்தனை, சுருக்கம் அல்லது சாராம்சப்படுத்தல் போன்ற திறன்கள் கற்றுக்கொடுக்கப்படுவதில்லை. கல்விமுறையின் அடிப்படை சிக்கல் இது. \n",
      "\n",
      "மாணவர்கள் வேலைக்குச் சென்றால், மூளையுழைப்புக்கு தயாரானவர்களாக இருப்பதற்காக, சலிப்பூட்டும் வேலைகளைச் செய்யும் மனித இயந்திரங்களாக மாறுகிறார்கள். இது அவர்களுக்கு வேலை கிடைப்பதற்கான காரணமாகும். \n",
      "\n",
      "கல்விமுறை ஆசிரியர்கள் மதிப்பெண் வழங்கும்போது வெளிப்படைத்தன்மையை பேணுவதில் கவனம் செலுத்துகின்றனர். மாணவர்கள் சுயமாக சிந்திக்கக் கற்றுக்கொள்ளுவதில்லை என்பதே இதற்குக் காரணம். \n",
      "\n",
      "அதனால், மாணவர்களுக்கு சிந்தனை, சாராம்சப்படுத்தல், நுண்சிந்தனை போன்றவற்றை கற்றுக்கொடுக்க வேண்டும். இவை இல்லையெனில், அவர்கள் எதிர்காலத்தில் மனித மூளையுழைப்பைச் செய்ய முடியாது, ஏனெனில் மற்ற அனைத்தையும் செயற்கை நுண்ணறிவு செய்யும். \n",
      "\n",
      "எனவே, நம் கல்லூரிகளின் நிலை மிகுந்த சிக்கலானதாக உள்ளது.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"நம்முடைய கல்லூரிகளின் நிலை என்ன?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "திருக்குறள் பற்றி தரப்பட்டுள்ள தகவல் எதுவும் கிடைக்கவில்லை.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"திருக்குறள் பற்றி கூறுக.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
